{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de80a02e-afe3-4a5d-b1eb-495b4ea83a3a",
   "metadata": {},
   "source": [
    "# Proof-of-Concept for Fine-Tuning Model with PEFT for Daily News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1156ba97-5325-4862-b86a-9c8fe10748b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install peft datasets\n",
    "!pip install mistral_inference\n",
    "#!pip install accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7477afc0-9f24-4c9c-bb37-1071645a4636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "import torch\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f31bbca-aa42-4731-9c43-e7c891ebd081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "#from accelerate import dispatch_model\n",
    "\n",
    "# Load spaCy model for Named Entity Recognition (NER)\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc75f983-0e20-4ff6-a431-b6c702cece23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.pytest_cache', 'newsies.log', 'docs', 'dist', 'newsies.egg-info', '.git', '.newsies.pid', 'nohup.out', 'scripts', 'build', 'LICENSE', 'newsies_err.log', 'daily_news', 'notebooks', '.gitignore', 'docker', 'requirements.txt', 'setup.py', 'tests', 'newsies', 'junit', '.vscode', 'README.md']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(\"..\")  # Adjust if needed\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from newsies.chromadb_client import ChromaDBClient, collections, get_all_headlines, find_ordinal\n",
    "from newsies import targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d911b62-fbf7-47c9-a8e4-69c0dd33d5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collection name: ap_news_2025-03-12\n",
      "there are 3727 stories in the collection\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Connect to ChromaDB and Retrieve Data\n",
    "def fetch_news_data():\n",
    "    client = ChromaDBClient()  # Update path\n",
    "    client.collection_name=f\"ap_news_{datetime.now().strftime(r'%Y-%m-%d')}\"\n",
    "    print(f\"collection name: {client.collection.name}\")\n",
    "    collection = client.collection\n",
    "    n  = collection.count()\n",
    "    print(f\"there are {n} stories in the collection\")\n",
    "    results = collection.get(where={\"target\":{\"$eq\":targets.DOCUMENT}}, limit=n)  \n",
    "    return results[\"documents\"], results[\"metadatas\"]\n",
    "\n",
    "news_docs, news_metadata = fetch_news_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a848c4ab-4304-40d6-b371-cd48b358496f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NEW YORK (AP) — Harvey Weinstein ‘s #MeToo retrial next month will largely be an abridged version of the original, with one big addition: a charge based on an allegation from a woman who wasn’t a part of the first case.\\nJust how the reprise of the disgraced movie mogul’s prosecution plays out is coming into focus at a hearing Wednesday, where a judge is set to issue rulings on a variety of issues, including the scope of accuser testimony and potential expert witnesses.\\nWeinstein, 72, was in court for the hearing, which started more than a hour late after Judge Curtis Farber met with the prosecution and defense behind closed doors to discuss matters still under seal.\\nThose included a prosecution request that two of the three accusers in the case be allowed to testify about other alleged encounters with Weinstein. They also discussed evidence of the accusers’ sexual history, which prosecutors say should be barred under New York’s Rape Shield Law.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d5e11ad-cfd3-400d-b1ae-b44bc2e59cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chunk_index': 0,\n",
       " 'collection': 'ap_news_2025-03-12',\n",
       " 'date': '2025-03-12',\n",
       " 'embedding_model': 'sentence-transformers/all-MiniLM-L6-v2',\n",
       " 'headline0': 'Harvey Weinstein appears in court  as judge weighs key rulings for his looming #MeToo retrial',\n",
       " 'headline1': 'Harvey Weinstein appears in court as judge weighs key rulings for his looming #MeToo retrial',\n",
       " 'headline2': 'Harvey Weinstein due in court for key rulings as his #MeToo retrial nears',\n",
       " 'section0': '',\n",
       " 'section1': 'politics',\n",
       " 'section2': 'technology',\n",
       " 'target': 'DOCUMENT',\n",
       " 'text': 'NEW YORK (AP) — Harvey Weinstein ‘s #MeToo retrial next month will largely be an abridged version of the original, with one big addition: a charge based on an allegation from a woman who wasn’t a part of the first case.\\nJust how the reprise of the disgraced movie mogul’s prosecution plays out is coming into focus at a hearing Wednesday, where a judge is set to issue rulings on a variety of issues, including the scope of accuser testimony and potential expert witnesses.\\nWeinstein, 72, was in court for the hearing, which started more than a hour late after Judge Curtis Farber met with the prosecution and defense behind closed doors to discuss matters still under seal.\\nThose included a prosecution request that two of the three accusers in the case be allowed to testify about other alleged encounters with Weinstein. They also discussed evidence of the accusers’ sexual history, which prosecutors say should be barred under New York’s Rape Shield Law.',\n",
       " 'uri': './daily_news/20250312/harvey-weinstein-sexual-misconduct-metoo-retrial-2e8f3c99224cf5ad068e7ef5b5907b8d.txt',\n",
       " 'url': 'https://apnews.com/article/harvey-weinstein-sexual-misconduct-metoo-retrial-2e8f3c99224cf5ad068e7ef5b5907b8d'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_metadata[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ed00ef-c941-4811-8463-2779d22900a2",
   "metadata": {},
   "source": [
    "## Use Flan-T5-large to generate questions for each article and for the named entities in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc92e308-5182-472e-9cbe-ea3b9d193e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Generate Question-Answer Pairs using an LLM\n",
    "device = 0 if torch.cuda.is_available() else -1  # Use GPU if available\n",
    "qa_generator = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\", device=device)\n",
    "\n",
    "def extract_named_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities = list(set(ent.text for ent in doc.ents if ent.label_ in {\"PERSON\", \"ORG\", \"GPE\"}))\n",
    "    return entities\n",
    "\n",
    "def generate_qa_pairs(news_docs, news_metadata):\n",
    "    qa_data = []\n",
    "    question_prompts = []\n",
    "    entity_prompts = []\n",
    "    \n",
    "    for doc, meta in tqdm(zip(news_docs, news_metadata), total=len(news_docs), desc=\"Generating QA Prompts\"):\n",
    "        context = f\"{meta['section0'] or 'front-page'}: {doc}\" # in the front-page section is ''\n",
    "        if meta[\"section1\"] != \"N/A\":\n",
    "            context += f\"\\n{meta['section1']}: {doc}\"\n",
    "        if meta[\"section2\"] != \"N/A\":\n",
    "            context += f\"\\n{meta['section2']}: {doc}\"\n",
    "        \n",
    "        # Extract named entities from article\n",
    "        entities = extract_named_entities(doc)\n",
    "        \n",
    "        # Generate 3 diverse questions about the article\n",
    "        question_prompts.append(\n",
    "            f\"For the following question, return the section, headline, and URI: Generate 3 different questions about the following news article. \"\n",
    "            f\"Include questions that focus on key details, impacts, and reasons. \"\n",
    "            f\"News: {context}\"\n",
    "        )\n",
    "        \n",
    "        # Generate one question per named entity\n",
    "        for entity in entities:\n",
    "            entity_prompts.append(\n",
    "                f\"For the following question, return the section, headline, and URI: Generate a question about {entity} in relation to the following news article. \"\n",
    "                f\"News: {context}\"\n",
    "            )\n",
    "    \n",
    "    # Generate questions\n",
    "    print(datetime.now(), \"generate article questions\")\n",
    "    article_questions = qa_generator(question_prompts, max_length=50, truncation=True)\n",
    "    print(datetime.now(), \"generate entity questions\")\n",
    "    entity_questions = qa_generator(entity_prompts, max_length=50, truncation=True) if entity_prompts else []\n",
    "    print(datetime.now(), \"prompt generation complete\")\n",
    "    entity_idx = 0\n",
    "    for (doc, meta), article_question_output in tqdm(zip(zip(news_docs, news_metadata), article_questions), total=len(news_docs), desc=\"Processing QA Pairs\"):\n",
    "        questions = article_question_output[\"generated_text\"].split(\"\\n\")\n",
    "        \n",
    "        # Store article questions\n",
    "        qa_data.append({\n",
    "            \"questions\": questions,\n",
    "            \"context\": doc,\n",
    "            \"answer\": [{\"headline\": meta[\"headline0\"], \"uri\": meta[\"uri\"]}]\n",
    "        })\n",
    "        \n",
    "        # Store entity-based questions\n",
    "        entities = extract_named_entities(doc)\n",
    "        for entity in entities:\n",
    "            if entity_idx < len(entity_questions):\n",
    "                qa_data.append({\n",
    "                    \"questions\": [entity_questions[entity_idx][\"generated_text\"]],\n",
    "                    \"context\": doc,\n",
    "                    \"answer\": [{\"headline\": meta[\"headline0\"], \"uri\": meta[\"uri\"]}]\n",
    "                })\n",
    "                entity_idx += 1\n",
    "    \n",
    "    return qa_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728f2c57-df36-4144-bd98-43199ae7a2c4",
   "metadata": {},
   "source": [
    "### Generate the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46886282-d611-41dd-8019-2a0afb17e94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QA Prompts: 100%|████████████████████████████████████████████████████████████████████████| 2994/2994 [00:41<00:00, 71.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-12 13:54:31.306997 generate article questions\n"
     ]
    }
   ],
   "source": [
    "qa_data = generate_qa_pairs(news_docs, news_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c239ef8-c50b-4fb4-82a6-cf055bb0c164",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24f842ec-b7e4-43f6-90a3-b058925adf49",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'qa_dataset_2025-03-12.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df.to_dict(orient=\u001b[33m\"\u001b[39m\u001b[33mrecords\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Save dataset\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m#save_qa_to_parquet(qa_dataset)\u001b[39;00m\n\u001b[32m     12\u001b[39m \n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Load dataset\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m qa_dataset = \u001b[43mload_qa_from_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mload_qa_from_parquet\u001b[39m\u001b[34m(file_path)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_qa_from_parquet\u001b[39m(file_path=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mqa_dataset_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime.now().strftime(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.parquet\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df.to_dict(orient=\u001b[33m\"\u001b[39m\u001b[33mrecords\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.7/envs/newsies/lib/python3.12/site-packages/pandas/io/parquet.py:667\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[39m\n\u001b[32m    664\u001b[39m     use_nullable_dtypes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    665\u001b[39m check_dtype_backend(dtype_backend)\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.7/envs/newsies/lib/python3.12/site-packages/pandas/io/parquet.py:267\u001b[39m, in \u001b[36mPyArrowImpl.read\u001b[39m\u001b[34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m manager == \u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    265\u001b[39m     to_pandas_kwargs[\u001b[33m\"\u001b[39m\u001b[33msplit_blocks\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m path_or_handle, handles, filesystem = \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    274\u001b[39m     pa_table = \u001b[38;5;28mself\u001b[39m.api.parquet.read_table(\n\u001b[32m    275\u001b[39m         path_or_handle,\n\u001b[32m    276\u001b[39m         columns=columns,\n\u001b[32m   (...)\u001b[39m\u001b[32m    279\u001b[39m         **kwargs,\n\u001b[32m    280\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.7/envs/newsies/lib/python3.12/site-packages/pandas/io/parquet.py:140\u001b[39m, in \u001b[36m_get_path_or_handle\u001b[39m\u001b[34m(path, fs, storage_options, mode, is_dir)\u001b[39m\n\u001b[32m    130\u001b[39m handles = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    132\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[32m    133\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[32m   (...)\u001b[39m\u001b[32m    138\u001b[39m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[32m    139\u001b[39m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m     handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m     fs = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    144\u001b[39m     path_or_handle = handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.7/envs/newsies/lib/python3.12/site-packages/pandas/io/common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'qa_dataset_2025-03-12.parquet'"
     ]
    }
   ],
   "source": [
    "# Step 3: Serialize and Deserialize QA Dataset using Parquet\n",
    "def save_qa_to_parquet(qa_data, file_path=f\"qa_dataset_{datetime.now().strftime(r'%Y-%m-%d')}.parquet\"):\n",
    "    df = pd.DataFrame(qa_data)\n",
    "    df.to_parquet(file_path, index=False)\n",
    "\n",
    "def load_qa_from_parquet(file_path=f\"qa_dataset_{datetime.now().strftime(r'%Y-%m-%d')}.parquet\"):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    return df.to_dict(orient=\"records\")\n",
    "\n",
    "# Save dataset\n",
    "save_qa_to_parquet(qa_dataset)\n",
    "\n",
    "# Load dataset\n",
    "qa_dataset = load_qa_from_parquet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be0a530d-ff7c-4824-a59e-af080d2cc810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the main reason for the rise in food poisoning in November and December?',\n",
       " 'context': 'health: Ready or not, the holidays are here. It’s a time when many Americans accustomed to preparing simple meals find themselves responsible for safely serving multi-dish feasts.\\nIt’s no easy task. Outbreaks of some types of food poisoning tend to rise in November and December, according to the U.S. Centers for Disease Control and Prevention. Tainted turkey, undercooked stuffing and germ-laced gravy from holiday buffets have all led to past illnesses — and even deaths — CDC investigators have found.\\nIt can be tricky for occasional cooks to prepare big meals in a way that avoids the common hazards that can make people sick, said Donald Schaffner, a food science expert at Rutgers University.\\n“Cooking takes longer with big masses of food. Cooling takes longer with big masses of food,” said Schaffner, who co-hosts the food-safety podcast “Risky or Not?”\\nAP Washington correspondent reports a food science expert has tips for helping make a Thanksgiving feast safely.',\n",
       " 'answer': array([{'headline': 'Do not wash your turkey and other Thanksgiving tips to keep your food safe', 'uri': './daily_news/20250311/food-safety-holidays-3584c4cf4d6a7c8bf9d5d6b55e3af66b.txt'}],\n",
       "       dtype=object)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21da92a4-4ae2-4db7-9e10-da48d8249122",
   "metadata": {},
   "source": [
    "## Remove the Flan-T5 model from GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade04c69-1734-4a07-85b7-55731a8c2458",
   "metadata": {},
   "outputs": [],
   "source": [
    "del qa_generator\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16fa8987-5a1e-4b5a-ac82-b15e987ed1f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53d155a770645a08df9aee01274b3ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3526132fef9348ca896b4bb9b31c54ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params.json:   0%|          | 0.00/202 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a135f28e614c4799a11a387f2cc7fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model.v3:   0%|          | 0.00/587k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93d589c0fdb4a26b85135a0f3f4f05a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "consolidated.safetensors:   0%|          | 0.00/14.5G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/home/mpeters/mistral_models/7B-v0.3'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "mistral_models_path = Path.home().joinpath('mistral_models', '7B-v0.3')\n",
    "mistral_models_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "snapshot_download(repo_id=\"mistralai/Mistral-7B-v0.3\", allow_patterns=[\"params.json\", \"consolidated.safetensors\", \"tokenizer.model.v3\"], local_dir=mistral_models_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce414613-b437-47e1-97e0-40a936d7af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Prepare Data for Fine-Tuning\n",
    "def format_dataset(qa_dataset):\n",
    "    dataset = Dataset.from_pandas(pd.DataFrame([{ \"input_text\": item[\"question\"], \"output_text\": str(item[\"answer\"]) } for item in qa_dataset]))\n",
    "    return dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "split_dataset = format_dataset(qa_dataset)\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "test_dataset = split_dataset[\"test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5703a20-e102-486a-9975-3336affd5a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f80f250470449cb0f57d6ca4d649c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 5: Load Model and Apply LoRA Fine-Tuning\n",
    "base_model_name = \"mistralai/Mistral-7B-v0.3\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_name, torch_dtype=torch.float16, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072320d6-e9f7-45bb-98b8-6fa54c106b21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b266802f-7847-4268-85cd-88082b761896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mpeters/.pyenv/versions/3.12.7/envs/newsies/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_171144/3351051170.py:19: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-11 14:40:46,004] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "df: /home/mpeters/.triton/autotune: No such file or directory\n",
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/usr/bin/ld: cannot find -lcufile: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "No label_names provided for model class `PeftModel`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No columns in the dataset match the model's forward method signature. The following columns have been ignored: [output_text, input_text]. Please check the dataset and model. You may need to set `remove_unused_columns=False` in `TrainingArguments`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m      8\u001b[39m training_args = TrainingArguments(\n\u001b[32m      9\u001b[39m     output_dir=\u001b[33m\"\u001b[39m\u001b[33m./news_finetune_model\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m     per_device_train_batch_size=\u001b[32m1\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     optim=\u001b[33m\"\u001b[39m\u001b[33madamw_torch\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m )\n\u001b[32m     19\u001b[39m trainer = Trainer(\n\u001b[32m     20\u001b[39m     model=model,\n\u001b[32m     21\u001b[39m     args=training_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m     tokenizer=tokenizer,\n\u001b[32m     25\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.7/envs/newsies/lib/python3.12/site-packages/transformers/trainer.py:2241\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2239\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2240\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2242\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.7/envs/newsies/lib/python3.12/site-packages/transformers/trainer.py:2270\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2268\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCurrently training with a batch size of: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._train_batch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   2269\u001b[39m \u001b[38;5;66;03m# Data loader and number of training steps\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2270\u001b[39m train_dataloader = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_train_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2271\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_fsdp_xla_v2_enabled:\n\u001b[32m   2272\u001b[39m     train_dataloader = tpu_spmd_dataloader(train_dataloader)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.7/envs/newsies/lib/python3.12/site-packages/transformers/trainer.py:1011\u001b[39m, in \u001b[36mTrainer.get_train_dataloader\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1009\u001b[39m data_collator = \u001b[38;5;28mself\u001b[39m.data_collator\n\u001b[32m   1010\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_datasets_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(train_dataset, datasets.Dataset):\n\u001b[32m-> \u001b[39m\u001b[32m1011\u001b[39m     train_dataset = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_remove_unused_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtraining\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1013\u001b[39m     data_collator = \u001b[38;5;28mself\u001b[39m._get_collator_with_removed_columns(data_collator, description=\u001b[33m\"\u001b[39m\u001b[33mtraining\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.7/envs/newsies/lib/python3.12/site-packages/transformers/trainer.py:937\u001b[39m, in \u001b[36mTrainer._remove_unused_columns\u001b[39m\u001b[34m(self, dataset, description)\u001b[39m\n\u001b[32m    935\u001b[39m columns = [k \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m signature_columns \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m dataset.column_names]\n\u001b[32m    936\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m937\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    938\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo columns in the dataset match the model\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms forward method signature. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    939\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe following columns have been ignored: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(ignored_columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    940\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease check the dataset and model. You may need to set `remove_unused_columns=False` in `TrainingArguments`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    941\u001b[39m     )\n\u001b[32m    943\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m version.parse(datasets.__version__) < version.parse(\u001b[33m\"\u001b[39m\u001b[33m1.4.0\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    944\u001b[39m     dataset.set_format(\n\u001b[32m    945\u001b[39m         \u001b[38;5;28mtype\u001b[39m=dataset.format[\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m], columns=columns, format_kwargs=dataset.format[\u001b[33m\"\u001b[39m\u001b[33mformat_kwargs\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    946\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: No columns in the dataset match the model's forward method signature. The following columns have been ignored: [output_text, input_text]. Please check the dataset and model. You may need to set `remove_unused_columns=False` in `TrainingArguments`."
     ]
    }
   ],
   "source": [
    "# LoRA Configuration\n",
    "lora_config = LoraConfig(\n",
    "    r=8, lora_alpha=32, target_modules=[\"q_proj\", \"v_proj\"], lora_dropout=0.05, bias=\"none\"\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./news_finetune_model\",\n",
    "    per_device_train_batch_size=1,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    optim=\"adamw_torch\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9a62f6-8e30-4beb-8c5d-988d6484e435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Evaluate the Fine-Tuned Model\n",
    "def evaluate_model(sample_question):\n",
    "    inputs = tokenizer(sample_question, return_tensors=\"pt\").to(\"cuda\")\n",
    "    output = model.generate(**inputs, max_new_tokens=50)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "sample_question = qa_dataset[0][\"question\"]\n",
    "response = evaluate_model(sample_question)\n",
    "print(f\"Q: {sample_question}\\nA: {response}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
